{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/aiscuser/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/aiscuser/.local/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/portable_jupyter/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/portable_jupyter/lib/python3.12/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aiscuser/.local/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/aiscuser/.local/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aiscuser/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aiscuser/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aiscuser/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aiscuser/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/portable_jupyter/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/aiscuser/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/aiscuser/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/portable_jupyter/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>user2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.138980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>gpt_summary</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>query2item</td>\n",
       "      <td>coverage@5</td>\n",
       "      <td>0.242179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>sparse_query2item</td>\n",
       "      <td>coverage@5</td>\n",
       "      <td>0.406221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>title2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.994792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model               task      metric     value\n",
       "0  bge_m3_1          user2item       hit@5  0.138980\n",
       "1  bge_m3_1        gpt_summary       hit@5  0.105263\n",
       "2  bge_m3_1         query2item  coverage@5  0.242179\n",
       "3  bge_m3_1  sparse_query2item  coverage@5  0.406221\n",
       "4  bge_m3_1         title2item       hit@5  0.994792"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 定义根目录\n",
    "root_dir = \"output/xbox_infer\"\n",
    "\n",
    "# 用于存储整理后的数据\n",
    "data = []\n",
    "\n",
    "\n",
    "\n",
    "# 遍历根目录下的所有文件夹\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    \n",
    "    # 检查是否是文件夹\n",
    "    if os.path.isdir(folder_path):\n",
    "        # 定位all_metrics.jsonl文件\n",
    "        metrics_file = os.path.join(folder_path, \"all_metrics.jsonl\")\n",
    "        \n",
    "        # 读取jsonl文件\n",
    "        if os.path.exists(metrics_file):\n",
    "            with open(metrics_file, 'r') as f:\n",
    "                # 将metrics按模型和任务类型进行存储\n",
    "                for line in f:\n",
    "                    metric_data = json.loads(line)\n",
    "                    model = folder  # 以文件夹名称作为模型名称\n",
    "                    task_name = metric_data.get(\"task_name\", \"unknown_task\")\n",
    "                    metrics = metric_data.get(\"metrics\", {})\n",
    "                    for metric_name, metric_value in metrics.items():\n",
    "                        if metric_name ==\"hit@5\":\n",
    "                            data.append([model, task_name, metric_name, metric_value])\n",
    "                        if task_name in [\"query2item\", \"sparse_query2item\"]:\n",
    "                            if metric_name ==\"coverage@5\":\n",
    "                                data.append([model, task_name, metric_name, metric_value])\n",
    "\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"model\", \"task\", \"metric\", \"value\"])\n",
    "\n",
    "# 保存为CSV文件\n",
    "output_csv_path = \"output/all_models_metrics_filtered.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>user2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.138980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>gpt_summary</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>query2item</td>\n",
       "      <td>coverage@5</td>\n",
       "      <td>0.242179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>sparse_query2item</td>\n",
       "      <td>coverage@5</td>\n",
       "      <td>0.406221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>title2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.994792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>item2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.906528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>queryuser2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.874840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>misspell2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.941019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>gpt_misspell</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>gpt_summary_query</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>gpt_query</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.024896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>relativequery2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bge_m3_1</td>\n",
       "      <td>negquery2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.986661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model                task      metric     value\n",
       "0   bge_m3_1           user2item       hit@5  0.138980\n",
       "1   bge_m3_1         gpt_summary       hit@5  0.105263\n",
       "2   bge_m3_1          query2item  coverage@5  0.242179\n",
       "3   bge_m3_1   sparse_query2item  coverage@5  0.406221\n",
       "4   bge_m3_1          title2item       hit@5  0.994792\n",
       "5   bge_m3_1           item2item       hit@5  0.906528\n",
       "6   bge_m3_1      queryuser2item       hit@5  0.874840\n",
       "7   bge_m3_1       misspell2item       hit@5  0.941019\n",
       "8   bge_m3_1        gpt_misspell       hit@5  0.000000\n",
       "9   bge_m3_1   gpt_summary_query       hit@5  0.111111\n",
       "10  bge_m3_1           gpt_query       hit@5  0.024896\n",
       "11  bge_m3_1  relativequery2item       hit@5  1.000000\n",
       "12  bge_m3_1       negquery2item       hit@5  0.986661"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>subset</th>\n",
       "      <th>line_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>user2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.156340</td>\n",
       "      <td>train</td>\n",
       "      <td>55152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>user2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.156340</td>\n",
       "      <td>test</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>query2item</td>\n",
       "      <td>coverage@5</td>\n",
       "      <td>0.242882</td>\n",
       "      <td>train</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>query2item</td>\n",
       "      <td>coverage@5</td>\n",
       "      <td>0.242882</td>\n",
       "      <td>test</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>sparse_query2item</td>\n",
       "      <td>coverage@5</td>\n",
       "      <td>0.411528</td>\n",
       "      <td>test</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>title2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>train</td>\n",
       "      <td>2734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>title2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>test</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>item2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.961424</td>\n",
       "      <td>train</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>item2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.961424</td>\n",
       "      <td>test</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>queryuser2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.893480</td>\n",
       "      <td>train</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>queryuser2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.893480</td>\n",
       "      <td>test</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>misspell2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.959786</td>\n",
       "      <td>train</td>\n",
       "      <td>3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>misspell2item</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.959786</td>\n",
       "      <td>test</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>gpt_misspell</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bge-m3_v6</td>\n",
       "      <td>gpt_summary</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.132308</td>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model               task      metric     value subset  line_count\n",
       "0   bge-m3_v6          user2item       hit@5  0.156340  train       55152\n",
       "1   bge-m3_v6          user2item       hit@5  0.156340   test       50000\n",
       "2   bge-m3_v6         query2item  coverage@5  0.242882  train        1152\n",
       "3   bge-m3_v6         query2item  coverage@5  0.242882   test        1138\n",
       "4   bge-m3_v6  sparse_query2item  coverage@5  0.411528   test        1093\n",
       "5   bge-m3_v6         title2item       hit@5  0.997396  train        2734\n",
       "6   bge-m3_v6         title2item       hit@5  0.997396   test         384\n",
       "7   bge-m3_v6          item2item       hit@5  0.961424  train         863\n",
       "8   bge-m3_v6          item2item       hit@5  0.961424   test         674\n",
       "9   bge-m3_v6     queryuser2item       hit@5  0.893480  train       12000\n",
       "10  bge-m3_v6     queryuser2item       hit@5  0.893480   test       25000\n",
       "11  bge-m3_v6      misspell2item       hit@5  0.959786  train        3840\n",
       "12  bge-m3_v6      misspell2item       hit@5  0.959786   test         373\n",
       "13  bge-m3_v6       gpt_misspell       hit@5  0.953125   test          13\n",
       "14  bge-m3_v6        gpt_summary       hit@5  0.132308   test          19"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json  \n",
    "import pandas as pd\n",
    "\n",
    "root_dir = \"/home/aiscuser/RecAI/RecLM-emb/data/xbox\"\n",
    "tasks_count = []\n",
    "\n",
    "# 遍历 train 和 test 目录，读取每个任务的 jsonl 文件条数\n",
    "for subfolder in [\"train\", \"test\"]:\n",
    "    subfolder_path = os.path.join(root_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for jsonl_file in os.listdir(subfolder_path):\n",
    "            if jsonl_file.endswith(\".jsonl\"):\n",
    "                file_path = os.path.join(subfolder_path, jsonl_file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    line_count = sum(1 for line in f)\n",
    "                tasks_count.append([subfolder, jsonl_file.replace(\".jsonl\", \"\"), line_count])\n",
    "\n",
    "# 将任务计数数据转换为 DataFrame\n",
    "tasks_df = pd.DataFrame(tasks_count, columns=[\"subset\", \"task\", \"line_count\"])\n",
    "df = pd.read_csv(\"/home/aiscuser/RecAI/RecLM-emb/output/all_models_metrics_filtered.csv\")\n",
    "\n",
    "merged_df = pd.merge(df, tasks_df, how=\"left\", on=\"task\")\n",
    "\n",
    "# 输出到 CSV 文件\n",
    "output_csv_path = \"output/merged_models_metrics.csv\"\n",
    "merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# 展示前几行数据\n",
    "merged_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['train', 'queryuser2item', 12000],\n",
       " ['train', 'title2item', 2685],\n",
       " ['train', 'relativequery2item', 380],\n",
       " ['train', 'negquery2item', 2127],\n",
       " ['train', 'item2item', 889],\n",
       " ['train', 'gpt_data_v2', 20741],\n",
       " ['train', 'user2item', 55343],\n",
       " ['train', 'misspell2item', 3840],\n",
       " ['train', 'query2item', 1152],\n",
       " ['train', 'gpt_data', 847],\n",
       " ['test', 'queryuser2item', 25000],\n",
       " ['test', 'title2item', 384],\n",
       " ['test', 'relativequery2item', 76],\n",
       " ['test', 'negquery2item', 4349],\n",
       " ['test', 'sparse_query2item', 1082],\n",
       " ['test', 'item2item', 665],\n",
       " ['test', 'user2item', 30000],\n",
       " ['test', 'gpt_summary_query', 454],\n",
       " ['test', 'misspell2item', 366],\n",
       " ['test', 'query2item', 1127],\n",
       " ['test', 'gpt_query', 1547],\n",
       " ['test', 'gpt_summary', 227],\n",
       " ['test', 'gpt_misspell', 137]]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 pivot_table 将数据转换为所需格式\n",
    "pivot_df = merged_df.pivot_table(index='task', columns='subset', values='line_count', aggfunc='sum').reset_index()\n",
    "pivot_df.rename(columns={'train': 'train_count', 'test': 'test_count'}, inplace=True)\n",
    "\n",
    "# 遍历唯一的模型名称，创建每个模型的评分列\n",
    "models = df['model'].unique()\n",
    "\n",
    "# 用于存储每个模型的评分数据\n",
    "model_scores_list = []\n",
    "\n",
    "for model in models:\n",
    "    model_scores = df[df['model'] == model][['task', 'metric', 'value']].drop_duplicates()\n",
    "\n",
    "    # 保持 metric 列用于后续合并\n",
    "    model_scores_pivot = model_scores.pivot_table(index=['task', 'metric'], values='value').reset_index()\n",
    "    model_scores_pivot.columns = ['task', 'metric', f\"{model}\"]\n",
    "\n",
    "    # 将每个模型的评分数据加入列表中\n",
    "    model_scores_list.append(model_scores_pivot)\n",
    "\n",
    "# 将所有模型的评分数据逐步合并到一个数据框中\n",
    "merged_scores_df = model_scores_list[0]\n",
    "for model_scores in model_scores_list[1:]:\n",
    "    merged_scores_df = pd.merge(merged_scores_df, model_scores, on=['task', 'metric'], how='left')\n",
    "\n",
    "# 将行数数据与模型评分合并\n",
    "final_df = pd.merge(pivot_df, merged_scores_df, on='task', how='left')\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "output_csv_path = \"output/processed_metrics_summary.csv\"\n",
    "final_df.to_csv(output_csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>test_count</th>\n",
       "      <th>train_count</th>\n",
       "      <th>metric</th>\n",
       "      <th>bge-m3_v6</th>\n",
       "      <th>bge-m3_v5_50_200k</th>\n",
       "      <th>bge-m3_history_only</th>\n",
       "      <th>e5-v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_summary</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.132308</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.112308</td>\n",
       "      <td>0.124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user2item</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>220608.0</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>0.156340</td>\n",
       "      <td>0.144620</td>\n",
       "      <td>0.144620</td>\n",
       "      <td>0.158560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           task  test_count  train_count metric  bge-m3_v6  bge-m3_v5_50_200k  \\\n",
       "2   gpt_summary        76.0          NaN  hit@5   0.132308           0.105263   \n",
       "12    user2item    200000.0     220608.0  hit@5   0.156340           0.144620   \n",
       "\n",
       "    bge-m3_history_only     e5-v1  \n",
       "2              0.112308  0.124615  \n",
       "12             0.144620  0.158560  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['task'].isin(['gpt_summary', 'user2item'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['bge-m3-base', 'bge-m3_v4'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbge-m3-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbge-m3_v4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# ,\"test_count\",\"train_count\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['bge-m3-base', 'bge-m3_v4'] not in index\""
     ]
    }
   ],
   "source": [
    "final_df[[\"task\",\"metric\",\"bge-m3-base\",\"bge-m3_v4\"]] # ,\"test_count\",\"train_count\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
